name: Deploy Combined HAPI FHIR Server and Inferno, Load IG and Test Data

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main
  workflow_dispatch:

jobs:
  build_run_and_test:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        # Ensure the Dockerfile.combined and supervisord.conf are checked out

      # No Java setup needed on the runner if building in Docker
      # - name: Set up JDK ${{ matrix.java }} ...

      - name: Load Configuration
        id: load-config
        run: |
          echo "Loading configuration from config.properties"
          while IFS='=' read -r key value; do
            echo "$key=$value" >> $GITHUB_ENV
          done < config.properties

      - name: Debug Environment Variables
        run: |
          echo "IG_PACKAGE_ID: ${{ env.IG_PACKAGE_ID }}"
          echo "IG_PACKAGE_VERSION: ${{ env.IG_PACKAGE_VERSION }}"
          # HAPI_SERVER is now localhost inside the container
          # echo "HAPI_SERVER: ${{ env.HAPI_SERVER }}" # Likely not needed externally
          echo "TERMINOLOGY_SERVER: ${{ env.TERMINOLOGY_SERVER }}"
          echo "TESTKIT_REPO: ${{ env.TESTKIT_REP }}"
          # No separate docker network needed if running in one container
          # docker network create CITestnet

      - name: Build Combined HAPI and Inferno Image
        run: |
          # Pass TESTKIT_REPO as a build argument to Dockerfile
          docker build . -f Dockerfile.combined -t hapi-inferno-combined --build-arg TESTKIT_REPO_URL=${{ env.TESTKIT_REPO }}

      - name: Run Combined Container
        run: |
          # Run in detached mode, map ports
          # Use a predictable name like 'combined-server'
          docker run -d --name combined-server -p 8080:8080 -p 4567:4567 hapi-inferno-combined
          echo "Waiting for Combined Container to start..."
          docker ps

      - name: Wait for HAPI FHIR Server within Container to start
        run: |
          # Check HAPI on the mapped port 8080 on the runner's localhost
          until curl --silent --fail http://localhost:8080/fhir/metadata; do
            echo "Waiting for HAPI..."
            sleep 10
          done
          echo "HAPI FHIR Server is running within the container."

      - name: Wait for Inferno within Container to start
        run: |
          # Check Inferno on the mapped port 4567 on the runner's localhost
          until curl --silent --fail http://localhost:4567; do # Adjust URL if Inferno has a specific health endpoint
            echo "Waiting for Inferno..."
            sleep 10
          done
          echo "Inferno is running within the container."

      - name: Setup .NET SDK # For UploadFIG
        uses: actions/setup-dotnet@v3
        with:
          dotnet-version: '9.0.x'

      - name: Install UploadFIG
        run: dotnet tool install --global UploadFIG

      - name: Upload IG using UploadFIG (Targeting HAPI inside container)
        run: |
          # Target localhost:8080 as HAPI is mapped there
          UploadFIG -pid ${{ env.IG_PACKAGE_ID }} -pv ${{ env.IG_PACKAGE_VERSION }} -d http://localhost:8080/fhir --includeReferencedDependencies -reg ${{ env.TERMINOLOGY_SERVER }}

      # --- Test Data Loading (No change needed here, still targets mapped HAPI) ---
      - name: Clone Test Data
        run: git clone https://github.com/${{ env.TEST_DATA_REPO }}.git test_data

      - name: Load Test Data
        # This step uses TestDataClient which targets http://localhost:8080/fhir
        # It should work as before, targeting the HAPI instance inside the container via the mapped port.
        run: |
          set -x
          sudo apt-get update && sudo apt-get install -y gh unzip jq
          LATEST_RELEASE=$(gh api /repos/hl7au/au-fhir-test-data-utils/releases | jq -r '.[0].tag_name')
          echo "Latest Release Tag: $LATEST_RELEASE"
          ASSET_URL=$(gh api /repos/hl7au/au-fhir-test-data-utils/releases/tags/$LATEST_RELEASE | jq -r '.assets[] | select(.name == "TestDataClient-linux-x64.zip") | .browser_download_url')
          echo "Asset URL: $ASSET_URL"
          if [ -z "$ASSET_URL" ]; then echo "Error: No Linux zip found"; exit 1; fi
          wget "$ASSET_URL" -O TestDataClient.zip
          mkdir TestDataClientDir
          unzip TestDataClient.zip -d TestDataClientDir
          chmod +x TestDataClientDir/TestDataClient-linux-x64-binaries/TestDataClient
          items=("Patient" "HealthcareService" "Organization" "Location" "Practitioner" "PractitionerRole" "RelatedPerson" "Encounter" "AllergyIntolerance" "Condition" "Immunization" "Procedure" "Observation" "Medication" "MedicationRequest" "MedicationStatement" "Coverage" "Specimen" "CommunicationRequest" "Consent" "ServiceRequest" "Task")
          for item in "${items[@]}"; do
            echo "Loading data for: $item"
            "./TestDataClientDir/TestDataClient-linux-x64-binaries/TestDataClient" "$item" "$GITHUB_WORKSPACE/test_data/au-fhir-test-data-set/" "http://localhost:8080/fhir" "basic" "default"
          done
        env:
          GH_TOKEN: ${{ github.token }}

      # --- Inferno DB Migration and Testing (Executed INSIDE the container) ---
      - name: Set up Inferno Database (inside container)
        run: |
          # Use docker exec to run the command inside the running container
          docker exec combined-server bash -c "cd /app && bundle exec rake db:migrate"
          echo "Inferno database migration attempted."

      - name: Execute Inferno Tests (inside container)
        run: |
          # Use docker exec. Target HAPI at http://localhost:8080/fhir as it's inside the same container.
          # No need for --network CITestnet anymore.
          docker exec combined-server bash -c "cd /app && \
            bundle exec inferno execute \
            --suite au_core_v110_preview \
            --inputs \"url:http://localhost:8080/fhir\" patient_ids:baratz-toni,irvine-ronny-lawrence,italia-sofia,howe-deangelo,hayes-arianne,baby-banks-john,banks-mia-leanne location_ids:bobrester-medical-center,au-hospital organization_ids:dva-au,organization-medical-center-tc practitioner_ids:alderson-helene practitioner_role_ids:cardiologist-sallie-sutherland,bobrester-bob-gp \
            --outputter json > /tmp/inferno_results.json" # Output to a temp file inside container

      - name: Copy Inferno Results
        run: |
          # Copy results back from the container to the runner workspace
          docker cp combined-server:/tmp/inferno_results.json ./inferno_results.json
          echo "Inferno results copied."
          cat inferno_results.json # Optional: display results in log
